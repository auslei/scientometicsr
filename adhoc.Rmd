---
title: "Literature Review - Automated Compliance Check (in construction)"
output: pdf
---

```{r setup, include=FALSE, warning = F, echo = F}
source("./src/modules/upload_files/data.R")
source("./src/modules/network_analysis/util.R")
source("./src/modules/data_visualisation/ui_utils.R")
library(DT)
library(highcharter)
library(knitr)
library(kableExtra)
library(xtable)
library(igraph)
library(visNetwork)
library(wordcloud2)

knitr::opts_chunk$set(echo = F, warning = F)

# cleaning - search results from WOS
df <- read_wos_data_file("~/Downloads/savedrecs.txt") %>% 
      mutate(author = gsub(",", "", author)) %>%
      filter(publication_type == "Journal")

print(paste("loaded ", nrow(df), "rows..."))
```


# Summary
Search results are loaded with `r nrow(df)` articles. 

## Distribution by Web Of Science Categories

The *Web Of Science" library finely categorises research literature, where each literature may reside in multiple categories. The analysis for which is done via separate categories (as each of the document will contain), then counting unique articles. 

```{r categories}
df_summary <- df %>% select(doc_id, wos_category, doi, citations) %>% 
                  separate_rows(wos_category, sep = ";") %>% 
                  mutate(wos_category = trimws(wos_category)) %>% 
                  group_by(wos_category) %>% 
                  summarise(n = n_distinct(doi), avg_citations = floor(mean(citations))) %>% 
                  arrange(desc(n))

print("**Top 10 categories from search result**")

datatable(df_summary %>% head(10), 
          rownames = F,
          colnames = c("Research Area", "Number of Literatures", "Average Citations")) 

```

Below chart shows the distribution of the categories (top 20):

```{r categories_chart}

hchart(df_summary %>% head(20), "treemap", hcaes(x = wos_category, value = n, color = avg_citations)) 
```

## Authors review

This is to measure authors contributions, based on total publications, total citations and average citations. 

```{r authors}
df_au_summary <- df %>% group_by(author) %>%
  summarise(n = n_distinct(doi), citations = sum(citations)) %>% arrange(desc(n)) 

kable(df_au_summary %>% head(15), rows.names = T,
      col.names = c("Authors", "Number of Literatures", "Total Citations") , format = "html") 
      # kable_styling(full_width = F,
      #              font_size = 12,
      #              position = "left")
```

The below shows distribution of the number of articles:

```{r author_summary}
  print("*Stats of authors articles*")
  print((t(summary(df_au_summary))))
```

## Distribution of # of Papers
```{r pressure, echo=FALSE}
# highchart() %>%
#     hc_xAxis(type = "category") %>%
#     hc_add_series_list(data_to_boxplot(data = df_au_summary, add_outliers = F, variable = n, name = "No. of Publications")) %>%
#     hc_add_series_list(data_to_boxplot(data = df_au_summary, variable = citations, name = "Total Citations"))

#df_au_summary <- 

hchart(density(df_au_summary$n), type = "area", name = "Distribution of Publications")
#hchart(df_au_summary$n, name = "Distribution of Publications")
    
```


## authors and citations

```{r authors_citations}
outersect <- function(x, y) {
  sort(c(setdiff(x, y),
         setdiff(y, x)))
}

# generate reference table
df_ref <- generate_reference_table(df)

df_ref_exclud_self_ref <- df_ref %>% filter(author != referenced_author)
  
core_authors <- intersect(df_ref$author, df_ref$referenced_author) # this is to ensure referenced author also published in the area

print(paste(length(core_authors), "/", length(unique(df_ref$author)), " have both publish an article and been cited."))

df_ref %>% 
      group_by(referenced_author, year) %>% 
      summarise(n_refs = n_distinct(doi)) %>% 
      arrange(desc(year), desc(n_refs))

authors_not_referenced <- outersect(core_authors, df_ref$author)

irrelevant_authors <- df %>% filter(author %in% authors_not_referenced) %>% 
                    select(author, publication, year, title, citations) %>% 
                    mutate(is_eng_cons = ifelse(str_detect(tolower(publication), "civil|construction|engin"), 1, 0))

# eng authors
eng_authors <- irrelevant_authors %>% filter(is_eng_cons == 1) %>% pull(author)
irrelevant_authors_summary <- irrelevant_authors %>% 
                              group_by(author) %>% 
                              filter(author %in% eng_authors) %>%
                              summarise(n=n_distinct(title), total_citation = sum(citations)) %>%   
                              arrange(desc(total_citation), desc(n))


a <- irrelevant_authors_summary$author %>% head(10)
irrelevant_authors %>% filter(author %in% a)

#hchart(irrelevant_authors_summary %>% head(20), "column", hcaes(x = publication, y = n)) 


kable(irrelevant_authors %>% 
        filter(author %in% a) %>%
        select(publication, author, year, title, citations) %>%
        arrange(desc(citations)), 
        row.names = T,
        col.names = c("Publication", "Author", "Year", "Title", "No. of Citations")
      )

```

## calculate author scores:

$S = \sum_{i=1}^{n}\alpha^{(Y-y_i)}{c}_i$

```{r auuthor_score}
sample_author <- df %>% 
  filter(author == "Zhong, BT") %>% 
  select(year, title, citations) %>% arrange(desc(year))

kable(sample_author)

get_author_score <- function(df, this_year = 2022, alpha = 0.9){
  df %>% filter(!is.na(year)) %>% 
    mutate(s = alpha^(this_year-year) * citations) %>% 
    group_by(author) %>% summarise(score = floor(sum(s)), total_citation = sum(citations)) %>% 
    arrange(desc(score))
}

author_scores = get_author_score(df)

kable(author_scores %>% head(10), 
      rows.names = T,
      col.names = c("Author", "Score", "Total Citations") , format = "html") 
```

### Pre-2000 authors, citations
```{r}
df %>% filter(year <2010) %>% 
  select(year, publication, author, title, doi, citations) %>% 
  head() %>% 
  arrange(desc(citations)) %>% 
  kable(row.names = T, col.names = c("Year", "Journal", "Author", "Title", 'DOI', "No. Of Citations"))
```

### Chart
```{r}
#hchart(density(df_au_summary$n), type = "area", name = "Distribution of Publications")
hchart(density(author_scores$total_citation), name = "Distribution of Publications")
```

## Building Networks

### Vertcies
Each of the vertex is an author:
- label
- score

### Edges
This is author links, try weighting

```{r edges_vertices}

# edge
v <- author_scores %>% mutate(author = gsub(",", "",  author)) %>%
     select(id = author, label = author, value = score, citations = total_citation) %>%
     filter(!(id %in% irrelevant_authors$author))
  
e <- df_ref %>% 
     select(from = author, to = referenced_author) %>%
     filter(from %in% v$id & to %in% v$id)

# this is to attempt to generate undirected graphs with weights
x <- e %>% mutate(x = ifelse(from > to, paste(to, from, sep = ";"), paste(from, to, sep = ";"))) %>% 
      group_by(x) %>% 
      summarise(weight = n(), .groups = "drop") %>%
      separate(x, c("from", "to"), sep = ";")  

g <- graph_from_data_frame(x, vertices = v, directed = F) #directed graph

wc_edge <- cluster_edge_betweenness(g)
print(paste(length(wc_edge), " edge communities found.."))

wc_louvain <- cluster_louvain(g)
print(paste(length(wc_louvain), " louvain communities found.."))

wc_walk <- cluster_walktrap(g)
print(paste(length(wc_walk), " walk communities found.."))

wc_infomap <- cluster_infomap(g)
print(paste(length(wc_infomap), " walk communities found.."))

wc <- wc_louvain

print(paste(length(wc), "communities found.."))

keep = which(table(wc$membership) > 1)
sub_g <- induced_subgraph(g, V(g)[(wc$membership %in% keep) | V(g)$value > 40])
print(paste(length(V(sub_g)), "verticies filtered out"))

sub_wc <- cluster_louvain(sub_g)
print(paste(length(sub_wc), " louvain communities found.."))

#list all communities from highest membership to lowest membership
communities <- table(sub_wc$membership) %>%
               as.data.frame(col.names = c("community", "members")) %>% 
               rename(community = Var1, members = Freq) %>% 
               arrange(desc(members)) 

plot_visnetwork(sub_g, sub_wc)

plot_community(sub_g, sub_wc, 1)

```

```{r further_cluster}
keep = which(table(wc$membership) > 10)
sub_g <- induced_subgraph(g, V(g)[(wc$membership %in% keep)])
print(paste(length(V(sub_g)), "verticies filtered out"))

sub_wc <- cluster_louvain(sub_g)
print(paste(length(sub_wc), " louvain communities found.."))

plot_visnetwork(sub_g, sub_wc)
```


```{r cluster analysis}

# assign authors to communities
author_communities <- as.data.frame(list(author=names(V(sub_g)), 
                                         community=sub_wc$membership), 
                                    stringsAsFactors=FALSE)

df_merged <- df %>% merge(author_communities, by = "author") %>% 
                    select(doc_id, author, community, title, abstract, year, 
                           raw_text, clean_text, formated_keywords, citations)

plot_wordcloud(filter(df_merged, community == 12), type = "keywords")

c1 <- df %>% filter(author %in% sub_wc[[1]])


bigram <- df_merged %>% 
            unnest_tokens(bigram, abstract, token = "ngrams", n = 2) %>%
            separate(bigram, c("word1", "word2"), sep = " ") %>%
            filter(!word1 %in% stop_words$word) %>%
            filter(!word2 %in% stop_words$word) %>%
            select(doc_id, author, community, word1, word2)

bigram_counts <- bigram %>% 
                 group_by(community) %>%
                 count(word1, word2, sort = TRUE) %>%
                 slice_max(order_by = n, n = 5)

keywords <- df_merged %>% 
            unnest_tokens(bigram, raw_text, to_lower = T, token = "ngrams", n = 2) %>%
            separate(bigram, c("word1", "word2"), sep = " ") %>%
            filter(!word1 %in% stop_words$word && !word2 %in% stop_words$word) %>%
            mutate(bigram = paste(word1, word2)) %>%
            #filter(!str_detect(word, "[^a-z_]")) %>%
            select(doc_id, author, community, bigram) 


keywords_summary <- keywords %>%
            group_by(community) %>%
            count(bigram, sort = T) %>%
            bind_tf_idf(bigram, community, n) %>% slice_max(order_by = tf_idf, n = 10)


ggplot(filter(keywords_summary, community %in% filter(communities, members > 10)$community), 
       aes(x = tf_idf, y = bigram)) +
  geom_col(show.legend = FALSE) + 
  facet_wrap(~community, scales = "free_y") +
  labs(x = NULL,
       y = NULL)


ggplot(filter(keywords_summary, community %in% filter(communities, members <= 10 & members > 2)$community), 
       aes(x = tf_idf, y = bigram)) +
  geom_col(show.legend = FALSE) + 
  facet_wrap(~community, scales = "free_y") +
  labs(x = NULL,
       y = NULL)
          
```


``` {r results = "asis"}
df_author_community <- author_scores %>% merge(author_communities, by = "author") 

for(i in c(1, 2, 12, 6, 178, 8, 40)) {
  cat(paste("## Top score for community ", i))
  t <- df_author_community %>% 
          filter(community == i) %>% 
          arrange(desc(score)) %>% 
          head(5) %>% 
          merge(df, by = "author") %>%
          select(author, title, citations) %>%
          arrange(desc(citations)) %>% head() %>%
          kable()
  
  cat(t)
}
```
```{r analyse_silos}
silos <- df_merged %>% filter(community %in% communities[7:nrow(communities),]$community)

keywords_summary_silo <- keywords %>% 
            filter(author %in% silos$author) %>%
            group_by(author) %>%
            count(bigram, sort = T) %>% 
            bind_tf_idf(bigram, author, n) #%>% slice_max(order_by = tf_idf, n = 10)

df_top_single_articles <- silos %>% select(author, title, citations, community) %>% arrange(desc(citations))

clip <- pipe("pbcopy", "w")

write.table(df_top_single_articles, file=clip)
close(clip)
```



```{r areas_for_visualistaion}
strong_connection <- c(1, 2, 12)
weak_connection <- c(8, 40)

V(sub_g)$community <- sub_wc$membership
connected_graph_strong <- induced_subgraph(sub_g, V(sub_g)$membership %in% strong_connection)

plot_visnetwork(connected_graph_strong)

#sub_g
#sub_wc


```